{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import etl.py module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add src to module search path \n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "\n",
    "if os.name == \"nt\":\n",
    "    path_separator = \"\\\\\"\n",
    "else:\n",
    "    path_separator = \"/\"\n",
    "    \n",
    "module_path = f\"{parent_dir}{path_separator}src\"\n",
    "sys.path.append(module_path)\n",
    "\n",
    "# import custom module\n",
    "from etl import DataPreprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use the module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the features of the module, we perform a very easy ETL pipeline, where we extract raw data from a csv, remove duplicate rows, and store the tranformed dataset in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class instantiation\n",
    "my_class = DataPreprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318345, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load raw data from csv\n",
    "file_path = f'..{path_separator}data{path_separator}raw{path_separator}interview_signup.csv'\n",
    "df = my_class.load_data_from_csv(file_path, \n",
    "                                 encoding='utf-8', \n",
    "                                 sep=',',\n",
    "                                 header=0,\n",
    "                                 dtype={'original_product_name': str,\n",
    "                                        'postcode': str,\n",
    "                                        'bundesland': str,\n",
    "                                        'total_bonus': 'float64',\n",
    "                                        'order_date': str})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318175, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete duplicate rows\n",
    "df = my_class.remove_duplicate_rows()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store preprocessed csv in folder data/processed\n",
    "file_path_processed = f\"..{path_separator}data{path_separator}processed{path_separator}demo_etl_module_processed.csv\"\n",
    "my_class.save_data_to_csv(file_path_processed, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
