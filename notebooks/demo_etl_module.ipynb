{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import etl.py module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add src to module search path \n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "\n",
    "if os.name == \"nt\":\n",
    "    path_separator = \"\\\\\"\n",
    "else:\n",
    "    path_separator = \"/\"\n",
    "    \n",
    "module_path = f\"{parent_dir}{path_separator}src\"\n",
    "sys.path.append(module_path)\n",
    "\n",
    "# import custom module\n",
    "from etl import DataPreprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use the module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the features of the module, we perform a very easy ETL pipeline, where we extract raw data from a csv, remove duplicate rows, and store the tranformed dataset in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f'..{path_separator}data{path_separator}raw{path_separator}interview_signup.csv'\n",
    "\n",
    "# class instantiation\n",
    "my_class = DataPreprocessing(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318345, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load raw data from csv\n",
    "sep = ','\n",
    "header = 0\n",
    "dtype = {'original_product_name': str,\n",
    "         'postcode'             : str,\n",
    "         'bundesland'           : str,\n",
    "         'total_bonus'          : 'float64',\n",
    "         'order_date'           : str}\n",
    "\n",
    "my_class.load_data_from_csv(# encoding='utf-8', \n",
    "                            sep=sep,\n",
    "                            header=header,\n",
    "                            dtype=dtype)\n",
    "my_class.df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['original_product_name', 'postcode', 'bundesland', 'total_bonus',\n",
       "       'order_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column names\n",
    "my_class.df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicate rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318175, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete duplicate rows\n",
    "my_class.remove_duplicate_rows()\n",
    "my_class.df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original_product_name        0\n",
       "postcode                     0\n",
       "bundesland               29521\n",
       "total_bonus                  0\n",
       "order_date                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of missing values for each column\n",
    "columns = list(my_class.df.columns)\n",
    "my_class.missing_values(columns).sum()\n",
    "\n",
    "# alt.: my_class.df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77271       Baden-Württemberg\n",
       "185532      Baden-Württemberg\n",
       "104805        Rheinland-Pfalz\n",
       "281760            Brandenburg\n",
       "227704            Brandenburg\n",
       "267961                 Bayern\n",
       "264005                Sachsen\n",
       "312390          Niedersachsen\n",
       "114214          Niedersachsen\n",
       "54115     Nordrhein-Westfalen\n",
       "Name: bundesland, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns logical index of all rows with missing state\n",
    "idx_missing_state = my_class.missing_values('bundesland')\n",
    "\n",
    "# Return sample of filled states\n",
    "my_class.df.loc[~idx_missing_state, 'bundesland'].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the invalid postcode cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of valid postcodes:  226865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "151539     9212.0\n",
       "171711    55120.0\n",
       "184509    57258.0\n",
       "90954     66119.0\n",
       "184141    24644.0\n",
       "155336    41065.0\n",
       "210185    98587.0\n",
       "175711    86978.0\n",
       "180833    77871.0\n",
       "161620    23627.0\n",
       "295899    64653.0\n",
       "92570      3249.0\n",
       "204672    45968.0\n",
       "92986     84034.0\n",
       "310886    32289.0\n",
       "20387        9661\n",
       "100614    44799.0\n",
       "170118    22081.0\n",
       "227894    83533.0\n",
       "220917    39524.0\n",
       "Name: postcode, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of valid postcodes: \", my_class.validate_postcode(\"postcode\").sum())\n",
    "idx_valid_postcodes = my_class.validate_postcode(\"postcode\")\n",
    "\n",
    "# return sample of 20 invalid postcodes\n",
    "my_class.df.loc[~idx_valid_postcodes, 'postcode'].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78598 entries were changed.\n",
      "\n",
      "Remaining invalid postcodes:  16610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "283411    7389\n",
       "172197    6749\n",
       "99452     6366\n",
       "24710     3096\n",
       "69345     9235\n",
       "16246     1662\n",
       "129440    7616\n",
       "208680    1277\n",
       "159313    4289\n",
       "127016    7743\n",
       "217390    6295\n",
       "153659    4880\n",
       "131270    8258\n",
       "48640     4889\n",
       "166348    7907\n",
       "175854    4347\n",
       "224756    6862\n",
       "77007     9353\n",
       "266439    6333\n",
       "200475    7318\n",
       "Name: postcode, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove decimals and check again\n",
    "my_class.remove_decimals('postcode')\n",
    "\n",
    "# remaining invalid postcodes\n",
    "idx_valid_postcodes = my_class.validate_postcode('postcode')\n",
    "print(\"Remaining invalid postcodes: \", my_class.df.shape[0] - idx_valid_postcodes.sum())\n",
    "\n",
    "# show sample of 20 remaining invalid cases\n",
    "my_class.df.loc[~idx_valid_postcodes, 'postcode'].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266922    92696JAVAS\n",
       "Name: postcode, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for postcodes with more than 5 digits\n",
    "idx_postcode_more_than_5 = my_class.df['postcode'].str.len()>5\n",
    "\n",
    "my_class.df.loc[idx_postcode_more_than_5, 'postcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16610\n"
     ]
    }
   ],
   "source": [
    "# remaining invalid postcodes\n",
    "print(my_class.df.shape[0] - my_class.validate_postcode('postcode').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert type \n",
    "my_class.df['bundesland'] = my_class.df['bundesland'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original_product_name      object\n",
       "postcode                   object\n",
       "bundesland               category\n",
       "total_bonus               float64\n",
       "order_date                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_class.df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 318175 entries, 0 to 318344\n",
      "Data columns (total 5 columns):\n",
      " #   Column                 Non-Null Count   Dtype   \n",
      "---  ------                 --------------   -----   \n",
      " 0   original_product_name  318175 non-null  object  \n",
      " 1   postcode               318175 non-null  object  \n",
      " 2   bundesland             288654 non-null  category\n",
      " 3   total_bonus            318175 non-null  float64 \n",
      " 4   order_date             318175 non-null  object  \n",
      "dtypes: category(1), float64(1), object(3)\n",
      "memory usage: 12.4+ MB\n"
     ]
    }
   ],
   "source": [
    "my_class.df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288654"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of valid German states \n",
    "my_class.validate_state('bundesland').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store preprocessed csv in folder data/processed\n",
    "file_path_processed = f\"..{path_separator}data{path_separator}processed{path_separator}demo_etl_module_processed.csv\"\n",
    "my_class.save_data_to_csv(file_path_processed, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
